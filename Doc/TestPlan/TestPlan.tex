\documentclass[12pt, titlepage]{article}

\usepackage{booktabs}
\usepackage{tabularx}
\usepackage{hyperref}
\hypersetup{
    colorlinks,
    citecolor=black,
    filecolor=black,
    linkcolor=red,
    urlcolor=blue
}
\usepackage[round]{natbib}

\input{../Comments}

\begin{document}

\title{RK Generator} 
\author{Alexander Schaap}
\date{\today}
	
\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
October 16 & 1.0 & Initial draft for presentation\\
%Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

\renewcommand{\arraystretch}{1.2}
\begin{tabular}{l l} 
  \toprule		
  \textbf{symbol} & \textbf{description}\\
  \midrule 
  T & Test\\
  \bottomrule
\end{tabular}\\

%\wss{symbols, abbreviations or acronyms -- you can reference the SRS tables if 
%needed}

\newpage

\tableofcontents

\listoftables

\listoffigures

\newpage

\pagenumbering{arabic}

This document ...

\section{General Information}

\subsection{Purpose}

This document specifies the (black-box) verification and validation tests for 
the RK Generator. The intended audience are testers aiming to test the system 
and developers maintaining the software. This document is expected to be 
updated when development of the system proceeds.

\subsection{Scope}

The scope of the testing of the RK Generator is restricted to correctness, in 
some cases within an expected margin of error. Performance, while implied, 
should also be verified. (This requires an unstaged version of the same code.)

\subsection{Overview of Document}

\section{Plan}
	
\subsection{Software Description}

\subsection{Test Team}

%\wss{Probably just you.  :-)}
Just me.
\subsection{Automated Testing Approach}

Automated tests exist primarily in the form of unit tests, though some 
``system'' tests will do black-box verification.

\subsection{Verification Tools}
%OUnit
%Make
%Continuous integration
%Code coverage - bisect_ppx
%\wss{Thoughts on what tools to use, such as the following: unit testing
%  framework, valgrind, static analyzer, make, continuous integration, test
%  coverage tool, etc.}

For unit tests, OUnit seems an obvious choice. For automating compilation and 
running unit tests as a primitive form of continuous integration, Make is 
sufficient. There appears to be a tool to measure code coverage, called 
bisect\_ppx. It remains to be seen how useful it is for MetaOCaml code.

% \subsection{Testing Schedule}
		
% See Gantt Chart at the following url ...

\subsection{Non-Testing Based Verification}

%\wss{List any approaches like code inspection, code walkthrough, symbolic
%  execution etc.  Enter not applicable if that is the case.}

Ideally, unit tests capture all the desired behaviour. \textbf{What do code 
inspection/walkthrough add? Also not practical as there are few MetaOCaml 
developers.}

\section{System Test Description}

Also known as black-box tests, system tests verify the software as a whole. 
This is done without assumed knowledge of the internal workings.

\subsection{Tests for Functional Requirements}

The intent is to test using problems with known solutions to get around oracle 
problem.
Results of other ODE solvers such as Matlab or Octave can be used for 
comparison purposes in case of unknown solutions.

\subsubsection{RK4}
		
\paragraph{Title for Test}

\begin{enumerate}

\item{Low-order-ODE\\}

Type: Functional, Dynamic
					
Initial State: 
					
Input: \textbf{a low order ODE for which an exact solution is known}
					
Output: The exact solution
					
How test will be performed: via OUnit
					
\item{High-order-ODE\\}

Type: Functional, Dynamic

Initial State: 

Input: \textbf{a high order ODE for which a fairly accurate solution is known}

Output: The solution, within a margin of error

How test will be performed: via OUnit

\item{Stiff-ODE\\}

Type: Functional, Dynamic

Initial State: 

Input: \textbf{a stiff ODE for which a fairly accurate solution is known}

Output: An inaccurate result

How test will be performed: via OUnit


\item{test-id2\\}

Type: Functional, Dynamic, Manual, Static etc.
					
Initial State: 
					
Input: 
					
Output: 
					
How test will be performed: 

\end{enumerate}

\subsubsection{RK2}

...

\subsection{Tests for Nonfunctional Requirements}

\subsubsection{Area of Testing1}
		
\paragraph{Title for Test}

\begin{enumerate}

\item{test-id1\\}

Type: 
					
Initial State: 
					
Input/Condition: 
					
Output/Result: 
					
How test will be performed: 
					
\item{test-id2\\}

Type: Functional, Dynamic, Manual, Static etc.
					
Initial State: 
					
Input: 
					
Output: 
					
How test will be performed: 

\end{enumerate}

\subsubsection{Area of Testing2}

...

\subsection{Traceability Between Test Cases and Requirements}

% \section{Tests for Proof of Concept}

% \subsection{Area of Testing1}
		
% \paragraph{Title for Test}

% \begin{enumerate}

% \item{test-id1\\}

% Type: Functional, Dynamic, Manual, Static etc.
					
% Initial State: 
					
% Input: 
					
% Output: 
					
% How test will be performed: 
					
% \item{test-id2\\}

% Type: Functional, Dynamic, Manual, Static etc.
					
% Initial State: 
					
% Input: 
					
% Output: 
					
% How test will be performed: 

% \end{enumerate}

% \subsection{Area of Testing2}

% ...
				
\section{Unit Testing Plan}
		
\wss{Unit testing plans for internal functions and, if appropriate, output
  files}

Unit tests can be divided into two distinct parts. The first set verifies 
portions of the generator, while the second part has to verify the generated 
code.



\bibliographystyle{plainnat}

\bibliography{SRS}

\newpage

\section{Appendix}

This is where you can place additional information.

\subsection{Symbolic Parameters}

The definition of the test cases will call for SYMBOLIC\_CONSTANTS.
Their values are defined in this section for easy maintenance.

\subsection{Usability Survey Questions?}

This is a section that would be appropriate for some teams.

\end{document}